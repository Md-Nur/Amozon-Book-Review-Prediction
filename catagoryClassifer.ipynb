{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\r\n",
    "    POSITIVE = 'POSITIVE'\r\n",
    "    NEGATIVE = 'NEGATIVE'\r\n",
    "    NEUTRAL = 'NEUTRAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\r\n",
    "    def __init__(self,t,s):\r\n",
    "        self.text = t\r\n",
    "        self.score = s\r\n",
    "        self.sentiment = self.getSentiment()\r\n",
    "    def getSentiment(self):\r\n",
    "        if self.score <=2:\r\n",
    "            return Sentiment.NEGATIVE\r\n",
    "        elif self.score == 3:\r\n",
    "            return Sentiment.NEUTRAL\r\n",
    "        else: # for score 4 and 5\r\n",
    "            return Sentiment.POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ag'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\r\n",
    "i = 0\r\n",
    "filePath = 'Data\\Sentiment\\Books_small_10000.json'\r\n",
    "with open(filePath) as f:\r\n",
    "    for line in f:\r\n",
    "        # print(line)\r\n",
    "        # line = line.replace(\"\\'\", \"\\\"\")\r\n",
    "        # print(i)\r\n",
    "        # i+=1\r\n",
    "        review = json.loads(line)\r\n",
    "        # print(review['overall'])\r\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\r\n",
    "        # break\r\n",
    "reviews[0].text[:89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[4].sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,testing = train_test_split(reviews,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = [x.text for x in training]\r\n",
    "trainY = [y.sentiment for y in training]\r\n",
    "testX = [x.text for x in testing]\r\n",
    "testY = [y.sentiment for y in testing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of word Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 26615)\n",
      "(3300, 26615)\n"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer()\r\n",
    "# vector.fit(trainX)\r\n",
    "# trainVectorX = vector.transform(trainX)\r\n",
    "# vector.fit(testX)\r\n",
    "trainVectorX = vector.fit_transform(trainX)\r\n",
    "testVectorX = vector.transform(testX)\r\n",
    "print(trainVectorX.shape)\r\n",
    "print(testVectorX.shape)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\r\n",
    "svm = SVC(kernel='linear')\r\n",
    "svm.fit(trainVectorX,trainY)\r\n",
    "svm.predict(testVectorX[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "dtc = DecisionTreeClassifier(random_state=0)\r\n",
    "dtc.fit(trainVectorX,trainY)\r\n",
    "dtc.predict(testVectorX[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "gnb = GaussianNB()\r\n",
    "gnb.fit(trainVectorX.todense(),trainY)\r\n",
    "gnb.predict(testVectorX.todense()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "lor = LogisticRegression(random_state=0)#.fit(X, y)\r\n",
    "lor.fit(trainVectorX,trainY)\r\n",
    "lor.predict(testVectorX[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "rfc = RandomForestClassifier(max_depth=2, random_state=0)\r\n",
    "rfc.fit(trainVectorX,trainY)\r\n",
    "rfc.predict(testVectorX[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution (check accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\t\t\t 81.24242424242424\n",
      "Decision Tree:\t\t 76.87878787878788\n",
      "Naive Bayes:\t\t 65.87878787878788\n",
      "Logistic Regression:\t 84.0909090909091\n",
      "Random Forest:\t\t 83.84848484848484\n"
     ]
    }
   ],
   "source": [
    "print('SVM:\\t\\t\\t',svm.score(testVectorX,testY)*100)\r\n",
    "print('Decision Tree:\\t\\t',dtc.score(testVectorX,testY)*100)\r\n",
    "print('Naive Bayes:\\t\\t',gnb.score(testVectorX.todense(),testY)*100)\r\n",
    "print('Logistic Regression:\\t',lor.score(testVectorX,testY)*100)\r\n",
    "print('Random Forest:\\t\\t',rfc.score(testVectorX,testY)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\t\t\t [0.90738061 0.40268456 0.2656    ]\n",
      "Decision Tree:\t\t [0.87384177 0.19259259 0.15780446]\n",
      "Naive Bayes:\t\t [0.7996939  0.11851852 0.1260745 ]\n",
      "Logistic Regression\t [0.92139968 0.40983607 0.29250457]\n",
      "Random Forest\t\t [0.91214768 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\r\n",
    "print('SVM:\\t\\t\\t',f1_score(testY,(svm.predict(testVectorX)),average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE,Sentiment.NEUTRAL]))\r\n",
    "print('Decision Tree:\\t\\t',f1_score(testY,(dtc.predict(testVectorX)),average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE,Sentiment.NEUTRAL]))\r\n",
    "print('Naive Bayes:\\t\\t',f1_score(testY,(gnb.predict(testVectorX.todense())),average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE,Sentiment.NEUTRAL]))\r\n",
    "print('Logistic Regression\\t',f1_score(testY,(lor.predict(testVectorX)),average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE,Sentiment.NEUTRAL]))\r\n",
    "print('Random Forest\\t\\t',f1_score(testY,(rfc.predict(testVectorX)),average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE,Sentiment.NEUTRAL]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.count(Sentiment.NEUTRAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: ['POSITIVE']\n",
      "DTC: ['POSITIVE']\n",
      "GNB: ['POSITIVE']\n",
      "LOR: ['POSITIVE']\n",
      "RFC: ['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "funTest = ['Equal']\r\n",
    "FT = vector.transform(funTest)\r\n",
    "print('SVM:',svm.predict(FT))\r\n",
    "print('DTC:',dtc.predict(FT))\r\n",
    "print('GNB:',gnb.predict(FT.todense()))\r\n",
    "print('LOR:',lor.predict(FT))\r\n",
    "print('RFC:',rfc.predict(FT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Our model with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "paramiters = {'kernel':('linear','rbf'),'C':(1,4,8,16,32)}\r\n",
    "svm = SVC()\r\n",
    "clf = GridSearchCV(svm,paramiters,cv=5)\r\n",
    "clf.fit(trainVectorX,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(cv=5, error_score=nan,\r\n",
    "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\r\n",
    "                           class_weight=None, coef0=0.0,\r\n",
    "                           decision_function_shape='ovr', degree=3,\r\n",
    "                           gamma='scale', kernel='rbf', max_iter=-1,\r\n",
    "                           probability=False, random_state=None, shrinking=True,\r\n",
    "                           tol=0.001, verbose=False),\r\n",
    "             iid='deprecated', n_jobs=None,\r\n",
    "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')},\r\n",
    "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\r\n",
    "             scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1 = SVC(kernel='rbf')\r\n",
    "svm1.fit(trainVectorX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384848484848485"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1.score(testVectorX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\r\n",
    "with open('model\\sentimentClassifierSvm.pkl', 'wb') as f:\r\n",
    "    pickle.dump(svm1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model\\sentimentClassifierSvm.pkl', 'rb') as f:\r\n",
    "    loadedSvm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedSvm.predict(testVectorX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8409090909090909"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\r\n",
    "\r\n",
    "lor1 = LogisticRegression(random_state=None)#.fit(X, y)\r\n",
    "lor1.fit(trainVectorX,trainY)\r\n",
    "lor1.score(testVectorX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model\\sentimentClassifierLor.pkl', 'wb') as f:\r\n",
    "    pickle.dump(lor1,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model\\sentimentClassifierLor.pkl', 'rb') as f:\r\n",
    "    loadedLor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5843a13e7131a14c3c0e364f0390d6592a995e3082c3f83420ac4385eeb2370"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}